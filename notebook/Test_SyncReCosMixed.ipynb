{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(globals()['_dh'][0])\n",
    "os.chdir('..')\n",
    "print(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfft = 64\n",
    "sig_len = 4096 + 160\n",
    "osfactor = 1\n",
    "cos_waves = np.exp(1j*2*np.pi*osfactor*np.arange(nfft).reshape(-1,1)/nfft*(np.arange(sig_len).reshape(1,-1)))\n",
    "n_sc = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 420123\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 629.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from asteroid.engine import System\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "n_test = 1000\n",
    "\n",
    "nfft = 64\n",
    "sig_len = 4096 + 160\n",
    "osfactor = 1\n",
    "cos_waves = np.exp(1j*2*np.pi*osfactor*np.arange(nfft).reshape(-1,1)/nfft*(np.arange(sig_len).reshape(1,-1)))\n",
    "\n",
    "n_sc = 28\n",
    "def generate_sig(coeff=1, sig_type=0):\n",
    "    if sig_type == 0:\n",
    "        syms = coeff*(2*np.random.randint(2, size=(nfft, 1)) - 1)\n",
    "    else:\n",
    "        syms = coeff*(2*np.random.randint(4, size=(nfft,1)) - 3)/np.sqrt(5)\n",
    "    syms[0,:] = 0\n",
    "    syms[n_sc+1:,:] = 0\n",
    "    syms[nfft//2+1:,:] = np.flipud(syms[1:nfft//2,:])\n",
    "    sig_comp = syms * 1/np.sqrt(2*n_sc) * cos_waves\n",
    "    sig = sig_comp.sum(axis=0)\n",
    "    return sig, sig_comp, syms\n",
    "\n",
    "def add_noise(sig, noise_pow=0.01):\n",
    "    noise = np.sqrt(noise_pow)*np.random.randn(len(sig))\n",
    "    return sig + noise\n",
    "\n",
    "def add_interference(sig, sig_type=1):\n",
    "    # interference, _, _ = generate_sig(coeff=2)\n",
    "    interference, _, _ = generate_sig(coeff=4, sig_type=1)\n",
    "    return sig+interference\n",
    "\n",
    "def reconstruct_sig(syms):\n",
    "    sig_comp = syms * np.sqrt(2)/np.sqrt(n_sc) * cos_waves\n",
    "    sig = sig_comp.sum(axis=0)\n",
    "    return sig, sig_comp\n",
    "\n",
    "seed_everything(420123, workers=True)\n",
    "np.random.seed(420123)\n",
    "random.seed(420123)\n",
    "all_sig, all_sig_noisy = [], [] \n",
    "for _ in tqdm(range(n_test)):\n",
    "    sig, sig_comp, syms = generate_sig()\n",
    "    idx = 0#np.random.randint(64)\n",
    "    sig_noisy = add_interference(sig, sig_type=1)\n",
    "    all_sig.append(sig[idx:idx+sig_len-160])\n",
    "    all_sig_noisy.append(sig_noisy[idx:idx+sig_len-160])\n",
    "    \n",
    "window_len = sig_len - 160\n",
    "\n",
    "all_sig = np.array(all_sig).reshape(-1, 1, window_len).real\n",
    "all_sig_noisy = np.array(all_sig_noisy).reshape(-1, 1, window_len).real\n",
    "\n",
    "tensor_x = torch.Tensor(all_sig_noisy)\n",
    "tensor_y = torch.Tensor(all_sig)\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(tensor_x,tensor_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, num_workers=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  waveunet_longksz_20filters_5depth : MSE  -47.377   models/case3/waveunet_longksz_20filters_5depth/sinsep_4096/epoch=1999-step=11250000.ckpt\n",
      "Model  waveunet0 : MSE  -4.663   models/case3/waveunet0/sinsep_4096/epoch=186-step=1051875.ckpt\n",
      "Model  sudormrf : MSE  -12.855   models/case3/sudormrf/sinsep_4096/epoch=381-step=2148750.ckpt\n",
      "Model  dptnet : MSE  -3.548   models/case3/dptnet/sinsep_4096/epoch=68-step=388125.ckpt\n",
      "Model  dprnntasnet : MSE  -0.671   models/case3/dprnntasnet/sinsep_4096/epoch=21-step=123750.ckpt\n",
      "Model  convtasnet : MSE  -1.009   models/case3/convtasnet/sinsep_4096/epoch=16-step=95625.ckpt\n",
      "Model  waveunet_longksz_20filters_12depth : MSE  -38.625   models/case3/waveunet_longksz_20filters_12depth/sinsep_4096/epoch=816-step=4595625.ckpt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from waveunet import Waveunet\n",
    "from asteroid.models import SuDORMRFImprovedNet, DPTNet, DPRNNTasNet, ConvTasNet\n",
    "\n",
    "all_residual = {}\n",
    "for idx in range(7):\n",
    "    if idx == 0:\n",
    "        model = Waveunet(n_src=1, n_first_filter=20, depth=5)\n",
    "        model_name = 'waveunet_longksz_20filters_5depth'\n",
    "    elif idx == 1:\n",
    "        model = Waveunet(n_src=1, long_kernel_size=15, n_first_filter=1)\n",
    "        model_name = 'waveunet0'\n",
    "    elif idx == 2:\n",
    "        model = SuDORMRFImprovedNet(n_src=1)\n",
    "        model_name = 'sudormrf'\n",
    "    elif idx ==3:\n",
    "        model = DPTNet(n_src=1)\n",
    "        model_name = 'dptnet'\n",
    "    elif idx==4:\n",
    "        model = DPRNNTasNet(n_src=1)\n",
    "        model_name = 'dprnntasnet'\n",
    "    elif idx==5:\n",
    "        model = ConvTasNet(n_src=1)\n",
    "        model_name = 'convtasnet'\n",
    "\n",
    "    elif idx == 6:\n",
    "        model = Waveunet(n_src=1, n_first_filter=20, depth=12)\n",
    "        model_name = 'waveunet_longksz_20filters_12depth'\n",
    "        \n",
    "    folder_name = f\"models/case3/{model_name}/sinsep_4096/\"\n",
    "    # file_list = os.listdir(folder_name)\n",
    "    file_list = glob.glob(folder_name+\"*\")\n",
    "    file_list = sorted(file_list, key=lambda t: -os.stat(t).st_mtime)\n",
    "    file_list = [ fname for fname in file_list if fname.endswith('.ckpt')]\n",
    "    filename = file_list[0]\n",
    "    path_name = filename\n",
    "    \n",
    "    loss = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4, amsgrad=True)\n",
    "    system = System(model, optimizer, loss, test_loader, test_loader)\n",
    "\n",
    "    ckpt = torch.load(path_name, map_location=torch.device('cpu'))\n",
    "    system.load_state_dict(ckpt['state_dict'], strict=False)\n",
    "\n",
    "    system.eval()\n",
    "    with torch.no_grad():\n",
    "        sig_est = system(tensor_x)\n",
    "    residual = (sig_est - tensor_y).cpu().detach().numpy().squeeze()\n",
    "    all_residual[model_name] = residual\n",
    "    print(\"Model \", model_name,\": MSE \", f\"{10*np.log10(np.mean(np.mean(np.abs(residual)**2, axis=1))):.03f}\", \" \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(all_residual, open('tmp_output/case3_residual_outputs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-asteroid]",
   "language": "python",
   "name": "conda-env-.conda-asteroid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
